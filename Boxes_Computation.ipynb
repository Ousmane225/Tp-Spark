{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Boxes-Computation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ousmane225/Tp-Spark/blob/master/Boxes_Computation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GFCHQiXg4nO",
        "colab_type": "text"
      },
      "source": [
        "# Boxes Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Koa2wpg4nW",
        "colab_type": "text"
      },
      "source": [
        "In this exercise, you will use the TensorFlow object detection API to get bounding boxes and classes on images.\n",
        "\n",
        "But first, we need some installation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy4sEk0Yg4na",
        "colab_type": "text"
      },
      "source": [
        "## I. Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5KX0lyrg4ne",
        "colab_type": "text"
      },
      "source": [
        "We will here follow the installation guide of the API, that can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw9pgyycg4ni",
        "colab_type": "text"
      },
      "source": [
        "### I.1. Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM3QLPpMg4np",
        "colab_type": "text"
      },
      "source": [
        "The first thing to do is to install all needed dependencies (if not installed yet):\n",
        "- pip install --user Cython\n",
        "- pip install --user contextlib2\n",
        "- pip install --user pillow\n",
        "- pip install --user lxml\n",
        "- pip install --user jupyter\n",
        "- pip install --user matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neY9w431g4nr",
        "colab_type": "text"
      },
      "source": [
        "### I.2. Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdzIRkh4g4nv",
        "colab_type": "text"
      },
      "source": [
        "Now we will download the models (i.e. the architecture and trained weights of neural networks). They are available in the so called [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\n",
        "\n",
        "For this exercise, we will use first the **faster_rcnn_inception_v2_coco** model: download it.\n",
        "\n",
        "You should get a .tar.gz file, containing (among other files) `frozen-inference-graph.pb`: this is what we will use to perform object detection.\n",
        "\n",
        "So extract it in the `data/models` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA-Ptpc3se4L",
        "colab_type": "code",
        "outputId": "2f4003ba-3339-49b1-a38e-ab3c8d8a5fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!curl http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz --output faster_rcnn_inception_v2_coco.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  142M  100  142M    0     0   154M      0 --:--:-- --:--:-- --:--:--  153M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bl3LPxztlqg",
        "colab_type": "code",
        "outputId": "6217dca9-c319-4c3b-8e93-e3e06fdb536f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!tar xvzf faster_rcnn_inception_v2_coco.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "faster_rcnn_inception_v2_coco_2018_01_28/\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.index\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/checkpoint\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.meta\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/saved_model.pb\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/variables/\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UshAjmjg4n6",
        "colab_type": "text"
      },
      "source": [
        "We also need to clone the `models` part of the TensorFlow Object Detection API. To do so, open your terminal, and in the **root of the vivadata folder**, clone the repo with the following command:\n",
        "\n",
        "```\n",
        "git clone https://github.com/tensorflow/models.git\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIE_42QQuGSH",
        "colab_type": "code",
        "outputId": "f82e527f-ecd4-4a2e-857f-6b7484524287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects:  12% (1/8)\u001b[K\rremote: Counting objects:  25% (2/8)\u001b[K\rremote: Counting objects:  37% (3/8)\u001b[K\rremote: Counting objects:  50% (4/8)\u001b[K\rremote: Counting objects:  62% (5/8)\u001b[K\rremote: Counting objects:  75% (6/8)\u001b[K\rremote: Counting objects:  87% (7/8)\u001b[K\rremote: Counting objects: 100% (8/8)\u001b[K\rremote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 34088 (delta 2), reused 6 (delta 0), pack-reused 34080\u001b[K\n",
            "Receiving objects: 100% (34088/34088), 512.27 MiB | 34.57 MiB/s, done.\n",
            "Resolving deltas: 100% (21849/21849), done.\n",
            "Checking out files: 100% (2499/2499), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRY3l3tQg4n9",
        "colab_type": "text"
      },
      "source": [
        "Finally, **do not commit those files**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuvtPE2kg4oC",
        "colab_type": "text"
      },
      "source": [
        "### I.3. Protobuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrFocB3Og4oF",
        "colab_type": "text"
      },
      "source": [
        "Protobuf (for protocol buffer) is a Google system, that will be used for configuration.\n",
        "\n",
        "Go now in the newly cloned repo at the root of the vivadata folder `models/research`, and launch the configuration using protobuf:\n",
        "```\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "```\n",
        "\n",
        "You may need to install the protobuf compiler using the following command on Ubuntu: `sudo apt-get install protobuf-compiler`\n",
        "\n",
        "For MacOS use `brew install protobuf`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zib3neiCubSO",
        "colab_type": "code",
        "outputId": "a7b56a64-c550-4163-d1df-656a54047159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!sudo apt-get install protobuf-compiler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNNN3aVuw5e",
        "colab_type": "code",
        "outputId": "a41b4318-c7ca-438e-dc45-869af160dd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd models/research/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2q2YPGFu5aJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Et0FaovDdL",
        "colab_type": "code",
        "outputId": "607fa429-3f3b-4f59-ba71-95f096e37c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRDODwa8g4oI",
        "colab_type": "text"
      },
      "source": [
        "## II. Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFFAcCXug4oJ",
        "colab_type": "text"
      },
      "source": [
        "### II.1. Setting the paths to the trained graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV-5IT0Gg4oM",
        "colab_type": "text"
      },
      "source": [
        "First, we set the paths of the model we will use in a variable called `PATH_TO_CKPT`: this is the path to the `frozen_inference_graph.pb` that you downloaded in I.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVvdwFmDg4oP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TODO: define the variable PATH_TO_CKPT\n",
        "PATH_TO_CKPT = \"faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh37Mbs-jWSD",
        "colab_type": "text"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0aHDohjg4oa",
        "colab_type": "text"
      },
      "source": [
        "Next you have to set the paths to the labels: indeed labels are just numbers, but we want them to be strings so that we can understand! The table to do so is in the folder you cloned: `models/research/object_detection/data/mscoco_label_map.pbtxt`.\n",
        "\n",
        "Put that path into the variable `PATH_TO_LABELS`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofHyNzzGg4oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TODO: define the variable PATH_TO_LABELS\n",
        "PATH_TO_LABELS = \"models/research/object_detection/data/mscoco_label_map.pbtxt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u05ClAMQg4ok",
        "colab_type": "text"
      },
      "source": [
        "Have a look at this file. How many classes are there? Put that value into a variable called `NUM_CLASSES`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B3QKpceg4op",
        "colab_type": "code",
        "outputId": "79e385db-f23c-4faa-f345-0586dba24bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### TODO: define the variable NUM_CLASSES\n",
        "with open(PATH_TO_LABELS) as file:\n",
        "    txt = file.read()\n",
        "NUM_CLASSES = txt.count(\"display_name\")\n",
        "NUM_CLASSES"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVwtwmawg4ow",
        "colab_type": "text"
      },
      "source": [
        "### II.2. Testing object detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbjTuAIog4oz",
        "colab_type": "text"
      },
      "source": [
        "We made some utils functions for you, so that you will just have to put them together to do the object detection.\n",
        "\n",
        "First, with the following code, you will compute the graph with the trained weights you downloaded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4JZxmDcg4o2",
        "colab_type": "code",
        "outputId": "f2318721-aeda-4dfc-8027-94d953595ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "# Compute the graph\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMvN1v3lg4o-",
        "colab_type": "text"
      },
      "source": [
        "Then, you will have to use the functions `run_inference_for_single_image` provided in the `utils.py` file. This function is easy to find on the TensorFlow Object Detection API. Have a look at it and try to understand the big picture.\n",
        "\n",
        "Then use it on the provided test images: `image1.jpg`, `image2` and `image3.jpg`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AUJIWmNg4pD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TODO: Use run_inference_for_single_image to compute the object detection\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK0RiFR2g4pY",
        "colab_type": "text"
      },
      "source": [
        "Now have a look at the output dictionary, can you understand its content? Save them in pickle format, in the next part of the challenge we will display and post process them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UolqGJLmg4pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TODO: Save the output dicts in pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}