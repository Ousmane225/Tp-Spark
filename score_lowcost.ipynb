{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"metastore_db/db.lck\")\n",
    "    os.remove(\"metastore_db/dbex.lck\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def build_spark_session(app_name, memory='4g', executors=4):\n",
    "    return SparkSession.builder\\\n",
    "                      .appName(app_name)\\\n",
    "                      .config('spark.executor.memory', memory)\\\n",
    "                      .config('spark.executor.instances', executors)\\\n",
    "                      .getOrCreate()\n",
    "\n",
    "spark_session = build_spark_session(app_name='ok-google')\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l'objectif est de predire l'appentence des clients a des transport lowcoast.\n",
    "Pour cela, nous utiliserons la librairie Ml de spark"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perimetre: représente les identifaints des clients accessible à l'étude.\n",
    "histo_client: represente l'historique des données clients sur une période donnée\n",
    "histo_train: represente l'historique des données de commandes trains.\n",
    "histo_lowcost: represente l'historique des données de client lowcost (défini avec le métier).\n",
    "visites: représente l'historique des données de navigation des clients sur le site."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - lire les fichiers de données\n",
    "2 - identifier les variables continues et transformer leurs modalités en double.\n",
    "3 - joindre les differentes sources de données en se basant sur les données du périmètre (tous les individus du périmèetre devront apparaitre dans la jointure avec des valeurs NULL si nécessaire pour les colonnes en provenance d'autres sources).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - joindre les dataframe sur la clé ID_CLIENT en concervant tous les clients du périmètre.\n",
    "2 - compter le nombre de ID_CLIENT et vérifier qu'il correspond aux nombre d'ID_CLIENT dans la variable perimètre.\n",
    "3 - Caster les variables continues en double et sauvergarder alors le df obtenu dans le repertoire data sur le cluster.\n",
    "4 - Pour les variables catégorielles, créer une nouvelle variable qui prend la modalité de la variable courante si elle existe et \"NA\" sinon.\n",
    "5- Verifier la cohérence des variables continue. Par exemple pour une variable comme age mettre à -1 tous les ages <0 ou>120ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacer les valeurs manquantes par \"-1\" pour le variables categorielles et par la moyenne de la colone pour les variables continues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lire les fichiers de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perimetre = spark_session.read.csv(\"/home/ousmane/data_clients/sample_perimetre.csv\", header=True)\n",
    "histo_client_raw = spark_session.read.csv(\"/home/ousmane/data_clients/sample_histo_client.csv\", header=True)\n",
    "histo_train_raw = spark_session.read.csv(\"/home/ousmane/data_clients/sample_histo_train.csv\", header=True)\n",
    "histo_lowcost_raw = spark_session.read.csv(\"/home/ousmane/data_clients/sample_histo_lowcost.csv\", header=True)\n",
    "visites_raw = spark_session.read.csv(\"/home/ousmane/data_clients/sample_visites.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID_CLIENT='0023d2b0a410eb572de950217a2e0fc661955b5d'),\n",
       " Row(ID_CLIENT='0026decd53a30d9b3298d6f4072ad3936bf2ea71'),\n",
       " Row(ID_CLIENT='002f0b8e5d22360080866fe1e0e17dda67ff317c'),\n",
       " Row(ID_CLIENT='00352dc1e7e43436fc0f6a5f2b34bf48864f0372'),\n",
       " Row(ID_CLIENT='005a10c0d3a94096cf4040a8f1fd88fbedbdb8fc')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perimetre.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084217, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perimetre.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID_CLIENT='000843db32fbaecfbb047ca0bb04b1f9f4d9425a', anciennete='1550', recence_cmd='36', AGE=None, LBL_STATUT_CLT='Grand', LBL_GEO_AIR='Aéroports de Paris Orly', LBL_GRP_SEGMENT_NL='Spectateur', LBL_SEG_COMPORTEMENTAL='Chasseurs Bons Plans', LBL_GEO_TRAIN='Paris', LBL_SEGMENT_ANTICIPATION='Mixte', FLG_CMD_CARTE_1225='0'),\n",
       " Row(ID_CLIENT='001338752ea32d9de129c8f8bdf3e2224cf0bd71', anciennete='1667', recence_cmd='25', AGE='35.0', LBL_STATUT_CLT='Grand', LBL_GEO_AIR='Aéroport de Marseille Provence  (MRS)', LBL_GRP_SEGMENT_NL='Spectateur', LBL_SEG_COMPORTEMENTAL='Comportement Pro', LBL_GEO_TRAIN='Marseille', LBL_SEGMENT_ANTICIPATION='Anticipateur', FLG_CMD_CARTE_1225='0'),\n",
       " Row(ID_CLIENT='003fb9dca8de374386d0fa97b570950583111931', anciennete='395', recence_cmd='15', AGE='25.0', LBL_STATUT_CLT='Moyen moins', LBL_GEO_AIR='Aéroport de Lyon - Saint Exupéry', LBL_GRP_SEGMENT_NL='Spectateur', LBL_SEG_COMPORTEMENTAL='Rythmes scolaires', LBL_GEO_TRAIN='Lyon', LBL_SEGMENT_ANTICIPATION='Peu Anticipateur', FLG_CMD_CARTE_1225='1')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_client_raw.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_CLIENT',\n",
       " 'anciennete',\n",
       " 'recence_cmd',\n",
       " 'AGE',\n",
       " 'LBL_STATUT_CLT',\n",
       " 'LBL_GEO_AIR',\n",
       " 'LBL_GRP_SEGMENT_NL',\n",
       " 'LBL_SEG_COMPORTEMENTAL',\n",
       " 'LBL_GEO_TRAIN',\n",
       " 'LBL_SEGMENT_ANTICIPATION',\n",
       " 'FLG_CMD_CARTE_1225']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_client_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      LBL_STATUT_CLT|\n",
      "+--------------------+\n",
      "|         Moyen moins|\n",
      "|Non present dans ...|\n",
      "|    Nouveau prospect|\n",
      "|            Prospect|\n",
      "|          Tres petit|\n",
      "|                null|\n",
      "|               Petit|\n",
      "|             Inactif|\n",
      "|       Nouveau actif|\n",
      "|               Grand|\n",
      "|          Tres grand|\n",
      "|          Moyen plus|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "histo_client_raw.select(\"LBL_STATUT_CLT\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      LBL_STATUT_CLT|\n",
      "+--------------------+\n",
      "|         Moyen moins|\n",
      "|Non present dans ...|\n",
      "|    Nouveau prospect|\n",
      "|            Prospect|\n",
      "|          Tres petit|\n",
      "|                null|\n",
      "|               Petit|\n",
      "|             Inactif|\n",
      "|       Nouveau actif|\n",
      "|               Grand|\n",
      "|          Tres grand|\n",
      "|          Moyen plus|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "histo_client_raw.select(\"LBL_STATUT_CLT\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|LBL_GRP_SEGMENT_NL|\n",
      "+------------------+\n",
      "|              null|\n",
      "|            Eteint|\n",
      "|        Spectateur|\n",
      "|            Acteur|\n",
      "|        Non defini|\n",
      "|           Endormi|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "histo_client_raw.select(\"LBL_GRP_SEGMENT_NL\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|LBL_SEG_COMPORTEMENTAL|\n",
      "+----------------------+\n",
      "|                  null|\n",
      "|      Comportement Pro|\n",
      "|      Exclusifs Agence|\n",
      "|  Chasseurs Bons Plans|\n",
      "|  Anticipateurs Met...|\n",
      "|     Rythmes scolaires|\n",
      "|              Nouveaux|\n",
      "|      Sans contraintes|\n",
      "|         Mono-commande|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "histo_client_raw.select(\"LBL_SEG_COMPORTEMENTAL\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------------+\n",
      "|           ID_CLIENT|days_since_last_visit|      tx_conversion|\n",
      "+--------------------+---------------------+-------------------+\n",
      "|000843db32fbaecfb...|                  8.0| 0.1111111111111111|\n",
      "|001338752ea32d9de...|                  3.0|0.13043478260869565|\n",
      "|003fb9dca8de37438...|                 15.0|                1.0|\n",
      "|004efa6652e570ef6...|                 17.0|              0.125|\n",
      "|005dd0b718a8f4598...|                 15.0| 0.3333333333333333|\n",
      "+--------------------+---------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visites.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ecrire une fonction pour transformer les features quantitatives (\"anciennete\", \"recence_cmd\", \"AGE\", etc..) en float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identifier les variables continues et transformer leurs modalités en double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225']\n",
    "\n",
    "def cast_columns_of_df(df, cols_to_cast, col_to_keep, cast_type='double'):\n",
    "    \"\"\"cast continuous columns into double since all columns are \"\"\"\n",
    "    return df.select(col_to_keep + [(df[feature].cast(cast_type))\n",
    "                    for feature in cols_to_cast if 'ID_CLIENT' not in feature])\n",
    "\n",
    "histo_train = cast_columns_of_df(histo_train_raw, histo_train_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "histo_lowcost = cast_columns_of_df(histo_lowcost_raw, histo_lowcost_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "visites = cast_columns_of_df(visites_raw, visites_raw.columns,\n",
    "                             [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "histo_client = cast_columns_of_df(histo_client_raw,\n",
    "                                  [\"anciennete\", \"recence_cmd\", \"AGE\"],\n",
    "                                  client_cols_to_keep,\n",
    "                                 cast_type='double')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visites = cast_columns_of_df(visites,\n",
    "                                  [\"days_since_last_visit\"],\n",
    "                                  ['ID_CLIENT','tx_conversion'],\n",
    "                                 cast_type='int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('tx_conversion', 'double'),\n",
       " ('days_since_last_visit', 'int')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visites.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "faire une jointure entre les informations des différentes tables.\n",
    "NB: on conservera tous les clients de la table perimetre.\n",
    "    En effet, ce sont les cleints qu'on souhaite scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3) joindre les differentes sources de données en se basant sur les données du périmètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=perimetre\\\n",
    ".join(histo_client, on=\"ID_CLIENT\",how='left_outer')\\\n",
    ".join(histo_lowcost, on='ID_CLIENT',how='left_outer')\\\n",
    ".join(histo_train, on='ID_CLIENT',how='left_outer')\\\n",
    ".join(visites,on='ID_CLIENT',how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084217, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons le même nombre de ligne dans le DataFrame apres jointure que dans la table perimetre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combien a t'on de features quatitatives, qualitatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definissons une fonction qui prend en entrée un df et renvoie la liste des variables quantitatives et celle des variable qualitatives\n",
    "\n",
    "\n",
    "def variable_type(x):\n",
    "    qualif=[]\n",
    "    contin=[]\n",
    "    n_cont=0\n",
    "    n_quali=0\n",
    "    for i in x.dtypes:\n",
    "        if i[1]==\"string\":\n",
    "            qualif.append(i[0])\n",
    "            n_quali+=1\n",
    "        else:\n",
    "            contin.append(i[0])\n",
    "            n_cont+=1\n",
    "    return (contin,qualif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['anciennete',\n",
       "  'recence_cmd',\n",
       "  'AGE',\n",
       "  'flg_cmd_lowcost',\n",
       "  'flg_track_nl_lowcost',\n",
       "  'flg_track_nl',\n",
       "  'nb_od',\n",
       "  'mean_nb_passagers',\n",
       "  'mean_duree_voyage',\n",
       "  'mean_mt_voyage',\n",
       "  'mean_tarif_loisir',\n",
       "  'mean_classe_1',\n",
       "  'mean_pointe',\n",
       "  'mean_depart_we',\n",
       "  'tx_conversion',\n",
       "  'days_since_last_visit'],\n",
       " ['ID_CLIENT',\n",
       "  'LBL_STATUT_CLT',\n",
       "  'LBL_GEO_AIR',\n",
       "  'LBL_SEG_COMPORTEMENTAL',\n",
       "  'LBL_GEO_TRAIN',\n",
       "  'LBL_GRP_SEGMENT_NL',\n",
       "  'LBL_SEGMENT_ANTICIPATION',\n",
       "  'FLG_CMD_CARTE_1225'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types=variable_type(df)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_col=types[1]\n",
    "quanti_col=types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flg_cmd_lowcost'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quanti_col.pop(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_col.append('flg_cmd_lowcost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### les differentes modalites de la feature LBL_STATUT_CLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      LBL_STATUT_CLT|\n",
      "+--------------------+\n",
      "|         Moyen moins|\n",
      "|Non present dans ...|\n",
      "|    Nouveau prospect|\n",
      "|            Prospect|\n",
      "|          Tres petit|\n",
      "|                null|\n",
      "|               Petit|\n",
      "|             Inactif|\n",
      "|       Nouveau actif|\n",
      "|               Grand|\n",
      "|          Tres grand|\n",
      "|          Moyen plus|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"LBL_STATUT_CLT\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      " |-- LBL_STATUT_CLT: string (nullable = true)\n",
      " |-- LBL_GEO_AIR: string (nullable = true)\n",
      " |-- LBL_SEG_COMPORTEMENTAL: string (nullable = true)\n",
      " |-- LBL_GEO_TRAIN: string (nullable = true)\n",
      " |-- LBL_GRP_SEGMENT_NL: string (nullable = true)\n",
      " |-- LBL_SEGMENT_ANTICIPATION: string (nullable = true)\n",
      " |-- FLG_CMD_CARTE_1225: string (nullable = true)\n",
      " |-- anciennete: double (nullable = true)\n",
      " |-- recence_cmd: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- flg_cmd_lowcost: double (nullable = true)\n",
      " |-- flg_track_nl_lowcost: double (nullable = true)\n",
      " |-- flg_track_nl: double (nullable = true)\n",
      " |-- nb_od: double (nullable = true)\n",
      " |-- mean_nb_passagers: double (nullable = true)\n",
      " |-- mean_duree_voyage: double (nullable = true)\n",
      " |-- mean_mt_voyage: double (nullable = true)\n",
      " |-- mean_tarif_loisir: double (nullable = true)\n",
      " |-- mean_classe_1: double (nullable = true)\n",
      " |-- mean_pointe: double (nullable = true)\n",
      " |-- mean_depart_we: double (nullable = true)\n",
      " |-- tx_conversion: double (nullable = true)\n",
      " |-- days_since_last_visit: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quelles sont les features avec valeurs manquantes\n",
    "remplacer les valeurs manquantes par -1 pour toutes les features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  les features avec valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
       "      <th>LBL_GEO_TRAIN</th>\n",
       "      <th>LBL_GRP_SEGMENT_NL</th>\n",
       "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
       "      <th>FLG_CMD_CARTE_1225</th>\n",
       "      <th>anciennete</th>\n",
       "      <th>recence_cmd</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_od</th>\n",
       "      <th>mean_nb_passagers</th>\n",
       "      <th>mean_duree_voyage</th>\n",
       "      <th>mean_mt_voyage</th>\n",
       "      <th>mean_tarif_loisir</th>\n",
       "      <th>mean_classe_1</th>\n",
       "      <th>mean_pointe</th>\n",
       "      <th>mean_depart_we</th>\n",
       "      <th>days_since_last_visit</th>\n",
       "      <th>tx_conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78998</td>\n",
       "      <td>162977</td>\n",
       "      <td>155160</td>\n",
       "      <td>163010</td>\n",
       "      <td>79522</td>\n",
       "      <td>157822</td>\n",
       "      <td>10283</td>\n",
       "      <td>55</td>\n",
       "      <td>1484</td>\n",
       "      <td>...</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>62370</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>220485</td>\n",
       "      <td>220485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENT  LBL_STATUT_CLT  LBL_GEO_AIR  LBL_SEG_COMPORTEMENTAL  \\\n",
       "0          0           78998       162977                  155160   \n",
       "\n",
       "   LBL_GEO_TRAIN  LBL_GRP_SEGMENT_NL  LBL_SEGMENT_ANTICIPATION  \\\n",
       "0         163010               79522                    157822   \n",
       "\n",
       "   FLG_CMD_CARTE_1225  anciennete  recence_cmd  ...  nb_od  mean_nb_passagers  \\\n",
       "0               10283          55         1484  ...  49927              49927   \n",
       "\n",
       "   mean_duree_voyage  mean_mt_voyage  mean_tarif_loisir  mean_classe_1  \\\n",
       "0              49927           49927              62370          49927   \n",
       "\n",
       "   mean_pointe  mean_depart_we  days_since_last_visit  tx_conversion  \n",
       "0        49927           49927                 220485         220485  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select(*(sum(col(c).isNull().cast('int')).alias(c) for c in df.columns)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplaçons les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_value(dd,qualif_col,continu_col):\n",
    "    dict_mean={feat:dd.select(f.mean(dd[feat])).collect()[0][0]\n",
    "              for feat in continu_col}\n",
    "    return dd.select([f.when(dd[feature].isNotNull(),dd[feature])\\\n",
    "              .otherwise('-1').alias(feature) for feature in qualif_col]\\\n",
    "             +[f.when(dd[feature].isNotNull(), dd[feature])\\\n",
    "             .otherwise(dict_mean[feature]).alias(feature) for feature in continu_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=replace_missing_value(df,quali_col,quanti_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('LBL_STATUT_CLT', 'string'),\n",
       " ('LBL_GEO_AIR', 'string'),\n",
       " ('LBL_SEG_COMPORTEMENTAL', 'string'),\n",
       " ('LBL_GEO_TRAIN', 'string'),\n",
       " ('LBL_GRP_SEGMENT_NL', 'string'),\n",
       " ('LBL_SEGMENT_ANTICIPATION', 'string'),\n",
       " ('FLG_CMD_CARTE_1225', 'string'),\n",
       " ('flg_cmd_lowcost', 'string'),\n",
       " ('anciennete', 'double'),\n",
       " ('mean_nb_passagers', 'double'),\n",
       " ('flg_track_nl_lowcost', 'double'),\n",
       " ('days_since_last_visit', 'double'),\n",
       " ('flg_track_nl', 'double'),\n",
       " ('recence_cmd', 'double'),\n",
       " ('mean_depart_we', 'double'),\n",
       " ('nb_od', 'double'),\n",
       " ('mean_pointe', 'double'),\n",
       " ('mean_classe_1', 'double'),\n",
       " ('mean_mt_voyage', 'double'),\n",
       " ('tx_conversion', 'double'),\n",
       " ('mean_tarif_loisir', 'double'),\n",
       " ('AGE', 'double'),\n",
       " ('mean_duree_voyage', 'double')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
       "      <th>LBL_GEO_TRAIN</th>\n",
       "      <th>LBL_GRP_SEGMENT_NL</th>\n",
       "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
       "      <th>FLG_CMD_CARTE_1225</th>\n",
       "      <th>anciennete</th>\n",
       "      <th>recence_cmd</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_od</th>\n",
       "      <th>mean_nb_passagers</th>\n",
       "      <th>mean_duree_voyage</th>\n",
       "      <th>mean_mt_voyage</th>\n",
       "      <th>mean_tarif_loisir</th>\n",
       "      <th>mean_classe_1</th>\n",
       "      <th>mean_pointe</th>\n",
       "      <th>mean_depart_we</th>\n",
       "      <th>tx_conversion</th>\n",
       "      <th>days_since_last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENT  LBL_STATUT_CLT  LBL_GEO_AIR  LBL_SEG_COMPORTEMENTAL  \\\n",
       "0          0               0            0                       0   \n",
       "\n",
       "   LBL_GEO_TRAIN  LBL_GRP_SEGMENT_NL  LBL_SEGMENT_ANTICIPATION  \\\n",
       "0              0                   0                         0   \n",
       "\n",
       "   FLG_CMD_CARTE_1225  anciennete  recence_cmd  ...  nb_od  mean_nb_passagers  \\\n",
       "0                   0           0            0  ...      0                  0   \n",
       "\n",
       "   mean_duree_voyage  mean_mt_voyage  mean_tarif_loisir  mean_classe_1  \\\n",
       "0                  0               0                  0              0   \n",
       "\n",
       "   mean_pointe  mean_depart_we  tx_conversion  days_since_last_visit  \n",
       "0            0               0              0                      0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "df1.select(*(sum(col(c).isNull().cast('int')).alias(c) for c in df.columns)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_df(df):\n",
    "    ds = df.select('ID_CLIENT',\n",
    "    f.when(df.LBL_GEO_TRAIN.isin(['Toulouse', 'Lille', 'Dijon',\n",
    "                                  'Lyon', 'Marseille', 'Paris',\n",
    "                                  'Nice', 'Limoges','Rouen','Rennes',\n",
    "                                  'Montpellier', 'Bordeaux', 'Metz',\n",
    "                                  'Strasbourg']), df.LBL_GEO_TRAIN)\\\n",
    "               .otherwise('na').alias('geo_train'),\n",
    "    f.when(df.LBL_GEO_AIR.isin(['Aéroports de Paris Orly',\n",
    "                                'Aéroport de Bâle-Mulhouse / Bassel',\n",
    "                                'Aéroport Lille Lesquin', 'Aéroport de Rennes',\n",
    "                                'Aéroport de Nantes Atlantique',\n",
    "                                'Aéroport de Marseille Provence  (MRS)', \n",
    "                                'Aéroport de Bordeaux Mérignac',\n",
    "                                'Aéroports de Paris Roissy-Charles-de Gaulle', \n",
    "                                \"Aéroport de Nice Côte d'Azur\",\n",
    "                                'Aéroport de Strasbourg',\n",
    "                                'Aéroport de Lyon - Saint Exupéry', \n",
    "                                'Aéroport de Toulouse Blagnac']), df.LBL_GEO_AIR)\\\n",
    "               .otherwise('na').alias('geo_air'),\n",
    "    f.when(df.FLG_CMD_CARTE_1225 == '1', '1')\\\n",
    "                   .otherwise('0').alias('cc_jeunes'),\n",
    "    f.when(df.LBL_STATUT_CLT.isin(['Tres grand', 'Nouveau actif',\n",
    "                                   'Moyen moins', ' Prospect', ' Petit',\n",
    "                                   'Inactif', 'Tres petit',\n",
    "                                   'Nouveau prospect', 'Moyen plus',\n",
    "                                   'Grand']), df.LBL_STATUT_CLT)\\\n",
    "                   .otherwise('na').alias('segt_rfm'),\n",
    "    f.when(df.LBL_SEGMENT_ANTICIPATION.isin(['Peu Anticipateur', 'Tres Anticipateur',\n",
    "                                             'Anticipateur', 'Mixte', 'Non Anticipateur',\n",
    "                                             'Non Defini']), df.LBL_SEGMENT_ANTICIPATION)\\\n",
    "                   .otherwise('na').alias('segt_anticipation'),\n",
    "    f.when(df.LBL_SEG_COMPORTEMENTAL.isin(['Mono-commande',\n",
    "                                           'Comportement Pro',\n",
    "                                           'Exclusifs Agence', \n",
    "                                           'Anticipateurs Methodiques',\n",
    "                                           'Chasseurs Bons Plans', \n",
    "                                           'Rythmes scolaires', 'Nouveaux',\n",
    "                                           'Sans contraintes']),\n",
    "           df.LBL_SEG_COMPORTEMENTAL).otherwise('na').alias('segt_comportemental'), \n",
    "    f.when(df.LBL_GRP_SEGMENT_NL.isin(['Endormi', 'Spectateur', 'Acteur',\n",
    "                                       'Eteint', 'Non defini']),\n",
    "           df.LBL_GRP_SEGMENT_NL).otherwise('na').alias('segt_nl'),\n",
    "    f.when(((df.AGE > 0) & (df.AGE < 100)), df.AGE)\\\n",
    "                   .otherwise(-1).alias('age'),\n",
    "    f.when(df.recence_cmd >= 0, df.recence_cmd)\\\n",
    "                   .otherwise(-1).alias('recence_cmd'),\n",
    "    f.when(((df.mean_duree_voyage > 0) & (df.mean_duree_voyage < 750)),\n",
    "           df.mean_duree_voyage).otherwise(-1).alias('mean_duree_voyage'),\n",
    "    f.when(df.days_since_last_visit >= 0, df.days_since_last_visit)\\\n",
    "                   .otherwise(-1).alias('recence_visite'),\n",
    "    f.when(df.mean_mt_voyage > 0, df.mean_mt_voyage)\\\n",
    "                   .otherwise(-1).alias('mean_mt_voyage'),\n",
    "    f.when(df.anciennete >= 0, df.anciennete)\\\n",
    "                   .otherwise(-1).alias('anciennete'),\n",
    "    f.when(df.nb_od > 0, df.nb_od)\\\n",
    "                   .otherwise(-1).alias('nb_od'),\n",
    "    f.when(df.mean_nb_passagers > 0, df.mean_nb_passagers)\\\n",
    "                   .otherwise(-1).alias('mean_nb_passagers'),\n",
    "    f.when(df.mean_tarif_loisir >= 0, df.mean_tarif_loisir)\\\n",
    "                   .otherwise(-1).alias('mean_tarif_loisir'),\n",
    "    f.when(df.mean_classe_1 >= 0, df.mean_classe_1)\\\n",
    "                   .otherwise(-1).alias('mean_classe_1'),\n",
    "    f.when(df.mean_pointe >= 0, df.mean_pointe)\\\n",
    "                   .otherwise(-1).alias('mean_pointe'),\n",
    "    f.when(df.mean_depart_we >= 0, df.mean_depart_we)\\\n",
    "                   .otherwise(-1).alias('mean_depart_we'),\n",
    "    f.when(df.tx_conversion >= 0, df.tx_conversion)\\\n",
    "                   .otherwise(-1).alias('tx_conversion'),\n",
    "    f.when(df.flg_cmd_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_cmd_lowcost'),\n",
    "    f.when(df.flg_track_nl_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl_lowcost'), \n",
    "    f.when(df.flg_track_nl == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl'))\n",
    "    \n",
    "    return ds\n",
    "df1 = input_df(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  les differentes valeurs de notre label : flg_cmd_lowcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|flg_cmd_lowcost| count|\n",
      "+---------------+------+\n",
      "|              0|979911|\n",
      "|              1|104306|\n",
      "+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('flg_cmd_lowcost').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### features engineering et modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessed_df(df, label=\"flg_cmd_lowcostIndex\"):\n",
    "    max_values_to_define_str_cols = 10\n",
    "    id_col = 'ID_CLIENT'\n",
    "    \n",
    "    dty = dict(df.dtypes)\n",
    "    str_cols = [k for k, v in dty.items() if v == 'string']\n",
    "    str_cols.remove(id_col)\n",
    "    \n",
    "    for c in str_cols:\n",
    "        stringIndexer = StringIndexer(inputCol=c, outputCol=c+\"Index\")\n",
    "        model_str = stringIndexer.fit(df)\n",
    "        df = model_str.transform(df).drop(c)\n",
    "\n",
    "    input_cols = df.columns\n",
    "    input_cols.remove(id_col)\n",
    "    input_cols.remove(label)\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=input_cols,\n",
    "                            outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    \n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                   outputCol=\"indexedFeatures\", \n",
    "                   maxCategories=max_values_to_define_str_cols).fit(df)\n",
    "    return featureIndexer.transform(df), df\n",
    "\n",
    "\n",
    "data, dff = preprocessed_df(df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  prelevons un sample de data pour notre modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFS=data.sample(False,0.01,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10954, 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFS.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = LogisticRegression(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                        featuresCol=\"indexedFeatures\",elasticNetParam=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                                    featuresCol=\"indexedFeatures\",\n",
    "                                    maxDepth=15, numTrees=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(DF,clf,label):\n",
    "    \n",
    "    (trainingData, testData) = DF.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    fitting=clf.fit(trainingData)\n",
    "    prevision=fitting.transform(testData)\n",
    "    comparaison=prevision.select([\"prediction\",label]).rdd\n",
    "    metric=MulticlassMetrics(comparaison)\n",
    "    mat_conf=metric.confusionMatrix().toArray()\n",
    "    \n",
    "    accuracy=(mat_conf[0][0]+mat_conf[1][1])/mat_conf.sum()\n",
    "    rappel=mat_conf[0][0]/(mat_conf[0][0]+mat_conf[0][1])\n",
    "    precision=mat_conf[0][0]/(mat_conf[0][0]+mat_conf[1][0])\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"flg_cmd_lowcostIndex\",metricName=\"areaUnderROC\")\n",
    "    AUC=evaluator.evaluate(prevision)\n",
    "    \n",
    "    metrics = {\"precision\":precision,\"rappel\":rappel,\"accuracy\":accuracy,\"AUC\":AUC}\n",
    "    return (metrics,fitting,prevision,mat_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quelle est le label renseigne pour la modelisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le Label renseigné est : \"flg_cmd_lowcostIndex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "logis = compute_model(DFS,lr,\"flg_cmd_lowcostIndex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coefficients du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.0024, -0.0085, 0.0012, 0.0154, -0.0178, 0.0001, 0.1598, 0.3202, -0.513, -1.6196, -0.3941, 0.1074, -0.0961, -0.0735, 0.0796, -0.9185, 0.0177, -0.0783, -0.0657, -0.0329, 11.3727, 17.9912])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logis[1].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.96384,\n",
       " 'rappel': 0.9990049751243781,\n",
       " 'accuracy': 0.9650812763395545,\n",
       " 'AUC': 0.8858530366625076}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logis[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_for=compute_model(DFS,classifier,\"flg_cmd_lowcostIndex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluer les performance de notre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.9655515071215635,\n",
       " 'rappel': 1.0,\n",
       " 'accuracy': 0.9675202998126171,\n",
       " 'AUC': 0.9291852188308687}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predire alors les clients lowcoast sur un sample de data n'ayant pas servi à l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|flg_cmd_lowcostIndex|count|\n",
      "+--------------------+-----+\n",
      "|                 0.0| 2915|\n",
      "|                 1.0|  287|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_for[2].groupBy([\"flg_cmd_lowcostIndex\"]).count().show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
